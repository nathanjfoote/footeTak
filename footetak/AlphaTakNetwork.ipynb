{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76934c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dict{Any, Any}(\"obs\" => Dict{Any, Any}(\"Player: \" => 1, \"Board: \" => PyObject[PyObject [] PyObject [] PyObject []; PyObject [] PyObject [] PyObject []; PyObject [] PyObject [] PyObject []])), Dict{Any, Any}(\"info\" => 0))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using POMDPs\n",
    "using PyCall\n",
    "using Printf\n",
    "using StatsBase\n",
    "using ProgressMeter\n",
    "using Flux\n",
    "using BenchmarkTools\n",
    "\n",
    "include(\"footeAlphaTak.jl\")\n",
    "\n",
    "gym = pyimport(\"gym\")\n",
    "foote_tak = pyimport(\"foote_tak\")\n",
    "env = gym.make(\"Tak-v0\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e83b4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(91 => 64),                      \u001b[90m# 5_888 parameters\u001b[39m\n",
       "  var\"#41#44\"(),\n",
       "  Chain(\n",
       "    SkipConnection(\n",
       "      Chain(\n",
       "        Conv((3,), 64 => 64, pad=1),    \u001b[90m# 12_352 parameters\u001b[39m\n",
       "        BatchNorm(64, relu),            \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "        Conv((3,), 64 => 64, pad=1),    \u001b[90m# 12_352 parameters\u001b[39m\n",
       "        BatchNorm(64, relu),            \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "      ),\n",
       "    ),\n",
       "    SkipConnection(\n",
       "      Chain(\n",
       "        Conv((3,), 64 => 64, pad=1),    \u001b[90m# 12_352 parameters\u001b[39m\n",
       "        BatchNorm(64, relu),            \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "        Conv((3,), 64 => 64, pad=1),    \u001b[90m# 12_352 parameters\u001b[39m\n",
       "        BatchNorm(64, relu),            \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "      ),\n",
       "    ),\n",
       "    SkipConnection(\n",
       "      Chain(\n",
       "        Conv((3,), 64 => 64, pad=1),    \u001b[90m# 12_352 parameters\u001b[39m\n",
       "        BatchNorm(64, relu),            \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "        Conv((3,), 64 => 64, pad=1),    \u001b[90m# 12_352 parameters\u001b[39m\n",
       "        BatchNorm(64, relu),            \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "      ),\n",
       "    ),\n",
       "  ),\n",
       "  var\"#43#47\"{Chain{Tuple{Conv{1, 2, typeof(relu), Array{Float32, 3}, Vector{Float32}}, var\"#flattenLayer#46\", Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(tanh)}}, Chain{Tuple{Conv{1, 2, typeof(relu), Array{Float32, 3}, Vector{Float32}}, var\"#flattenLayer#46\", Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}}(Chain(Conv((1,), 64 => 64, relu), flattenLayer, Dense(64 => 1), tanh), Chain(Conv((1,), 64 => 64, relu), flattenLayer, Dense(64 => 126), softmax)),\n",
       ") \u001b[90m        # Total: 26 trainable arrays, \u001b[39m80_768 parameters,\n",
       "\u001b[90m          # plus 12 non-trainable, 768 parameters, summarysize \u001b[39m387.379 KiB."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ea8d9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_move_probabilities (generic function with 1 method)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_move_probabilities(root::MCTSNode, env)\n",
    "    valid_action_indices = [act[end] for act in env.get_valid_actions()]\n",
    "    probabilities = zeros(length(env.actions))\n",
    "    \n",
    "    total_visit_count = sum([child.visit_count for child in root.children])\n",
    "    \n",
    "    for child in root.children\n",
    "        if child.action[end] in valid_action_indices\n",
    "            probabilities[child.action[end]] = child.visit_count / total_visit_count\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return probabilities\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5783032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "self_play (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Part 1: Self-play #####\n",
    "function self_play(network, game_env, solver, num_games)\n",
    "    data = []\n",
    "\n",
    "    @showprogress for i in 1:num_games\n",
    "        game_env.reset()\n",
    "        game_history = []\n",
    "        reward_collected = 0\n",
    "\n",
    "        while !game_env.is_terminal()\n",
    "            \n",
    "            # Use MCTS to determine the move probabilities\n",
    "            node = solve(solver, game_env, network)\n",
    "            \n",
    "            move_probabilities = get_move_probabilities(node, game_env)\n",
    "\n",
    "            # Store the state, move probabilities, and current player\n",
    "            push!(game_history, (game_env.state, move_probabilities))\n",
    "            \n",
    "            action_index = argmax(get_move_probabilities(node, game_env))\n",
    "\n",
    "            # Make a move\n",
    "            _, reward_collected, _, _ = game_env.step(action_index)\n",
    "        end\n",
    "\n",
    "        # Determine the winner\n",
    "        #winner = get_winner(game_env, reward_collected)\n",
    "\n",
    "        # Add the game history and outcome to the training data\n",
    "        for move in game_history\n",
    "            push!(data, (move, reward_collected))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return data\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
